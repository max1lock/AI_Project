# Rapport d'Exp√©rimentation

## Introduction üìå

Ce rapport d√©taille les exp√©rimentations men√©es dans le cadre du projet d'entra√Ænement de mod√®les YOLO pour la d√©tection d'objets.

---

## Exp√©rimentations Conduites üõ†Ô∏è

Nous avons men√© plusieurs exp√©rimentations afin d'obtenir un mod√®le performant. Nos tests ont port√© sur diff√©rentes configurations d'hyperparam√®tres et sur l'utilisation de techniques de data augmentation. Nous avons √©galement explor√© l'effet du tuning automatique des hyperparam√®tres afin d'am√©liorer la convergence du mod√®le et d'optimiser sa capacit√© √† g√©n√©raliser sur de nouvelles donn√©es.

### 1. Configuration de Base üîß

Nous avons commenc√© par entra√Æner notre mod√®le YOLO11n avec des hyperparam√®tres standards. Cette configuration a permis d'atteindre le **meilleur fitness** de **0.30**, ce qui en fait notre r√©f√©rence principale pour les comparaisons ult√©rieures.

```yaml
model: "yolo11n.pt"
epochs: 150
patience: 20
batch: 16
imgsz: 640
device: "0"
workers: 8
exist_ok: True
optimizer: "AdamW"
lr0: 0.001
```

Le mod√®le a converg√© correctement et a montr√© des r√©sultats relativement stables sur les donn√©es de validation, bien qu'il soit encore loin d'une performance optimale pour une application pratique.

### 2. Test avec Data Augmentation et Hyperparam√®tres Avanc√©s üìä

Afin d'am√©liorer les performances du mod√®le, nous avons test√© des strat√©gies plus complexes, incluant la **data augmentation** (`mosaic`, `mixup`) ainsi que des modifications des hyperparam√®tres li√©s √† l'optimisation et au pr√©traitement des donn√©es.

```yaml
epochs: 150
patience: 20
batch: 32
imgsz: 640
workers: 8
exist_ok: true
cache: true
optimizer: "AdamW"
lr0: 0.0005
weight_decay: 0.0005
warmup_epochs: 3
mosaic: true
mixup: true
```

Cependant, contrairement √† nos attentes, cette configuration a entra√Æn√© une **baisse des performances** avec un **best fitness de 0.23**. Nous avons remarqu√© que l'ajout de `mosaic` et `mixup` compliquait l'apprentissage, probablement en raison de la g√©n√©ration d'assets entra√Ænant une mauvaise g√©n√©ralisation du mod√®le.

### 3. Tuning Automatique avec `model.tune` üéØ

Nous avons tent√© d'affiner encore davantage les performances du mod√®le en utilisant le tuning automatique des hyperparam√®tres via `model.tune`. Cette technique ajuste dynamiquement les param√®tres en fonction des performances obtenues au fil des it√©rations.

```python
model.tune(
    data=os.path.abspath("./config.yaml"),
    epochs=30,
    iterations=150,
    optimizer="AdamW",
    imgsz=640,
)
```

Toutefois, cette approche n'a pas apport√© les am√©liorations escompt√©es, et nous avons obtenu un **best fitness autour de 0.22**. Il semble que le tuning automatique peine √† trouver des combinaisons d'hyperparam√®tres pertinentes pour notre dataset sp√©cifique.

---

## Observations et Conclusions üîé

- **La configuration de base a donn√© les meilleurs r√©sultats (0.30)**, confirmant que les hyperparam√®tres standards sont plus adapt√©s √† notre t√¢che.
- **L'ajout de data augmentation a d√©grad√© les performances**, probablement √† cause de la complexit√© accrue des transformations appliqu√©es aux images.
- **L'entra√Ænement avec tuning automatique n'a pas permis de surpasser la configuration initiale**, indiquant une possible inad√©quation entre notre dataset et les param√®tres ajust√©s.
- **Nos r√©sultats restent insuffisants pour une application r√©elle**, le best fitness plafonnant √† 0.30.

---

## Pistes d'Am√©lioration üöÄ

Pour am√©liorer les performances du mod√®le, nous proposons plusieurs axes d'exploration :

- **Tester d'autres architectures YOLO** comme YOLOv11s, m, l, x , qui pourraient offrir de meilleures r√©sultats.
- **Ajuster la taille des images** (`imgsz: 768` ou `896`) afin d'am√©liorer la r√©solution des objets d√©tect√©s et √©viter les pertes d'information.
- **R√©√©quilibrer les classes du dataset** pour s'assurer que la distribution des donn√©es ne biaise pas l'entra√Ænement du mod√®le.
- **Exp√©rimenter avec des optimisateurs diff√©rents**, comme `SGD` avec un `momentum` ajust√©, afin d'am√©liorer la convergence.
- **Essayer des strat√©gies de data augmentation plus l√©g√®res**, telles que le `flip`, la `rotation` et l'ajout de bruit, plut√¥t que des techniques trop agressives.

---

## Lien vers les Mod√®les üîó

- **Meilleur mod√®le atteint** : [Voir sur Picsellia](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/model/01936428-4088-7381-8513-9813994a8a7b/version/0194e6c4-fdee-7c35-940c-06fc97804a6a)
- **Dernier mod√®le utilis√© en inf√©rence** : [Voir sur Picsellia](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/model/01936428-4088-7381-8513-9813994a8a7b/version/0194ea70-a358-7692-bb96-440be99705a9)

---

## Conclusion üéØ

Malgr√© de nombreuses exp√©rimentations et ajustements, notre mod√®le **n‚Äôa pas atteint une performance satisfaisante**. Nos tests indiquent que **les hyperparam√®tres de base restent les plus efficaces** compar√©s aux configurations plus complexes. Toutefois, des pistes d‚Äôam√©lioration subsistent, notamment en ajustant **l‚Äôarchitecture du mod√®le, la taille des images et les strat√©gies de pr√©traitement**.

Nous recommandons d'explorer ces directions pour esp√©rer une meilleure convergence et une am√©lioration significative des performances du mod√®le. üöÄ
